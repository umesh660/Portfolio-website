---
layout: page
title: Projects
---
<h2 class="title" >PROJECTS</h2>
<!-- <section class="list">
    {% for post in site.posts %}
        {% if post.projects %}
            <div class="item {% if post.star %}star{% endif %}" >
                <a class="url" href="{% if post.externalLink %}{{ post.externalLink }}{% else %}{{ site.url }}{{ post.url }}{% endif %}">
                    <h3 class="title" style="font-family: 'Noto Serif';">{{ post.ct }}. {{ post.title }}</h3>
                </a>
            </div>
        {% endif %}
    {% endfor %} -->

    <ol class="skill-list" style="font-family: 'Comic Sans MS';">
    
        
        <li>
  <h4 style="font-family: 'Comic Sans MS';">
    <a href="https://github.com/umesh660/Image_Classification">Image Classification Model Development</a> [Python, TensorFlow, Keras]
  </h4>
</li>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Developed an image classification model using Python in a Google Colab environment leveraging TensorFlow and Keras libraries. The project aimed to classify images into two categories: "Happy" and "Sad".
</p>
<ul style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  <li><b>Data Preprocessing:</b> Implemented data preprocessing steps including image extension validation and removal of unsupported image files. Ensured data integrity and compatibility for model training.</li>
  <li><b>Model Development:</b> Constructed a convolutional neural network (CNN) architecture using Keras Sequential API. Designed the model with convolutional layers, max-pooling layers, and dense layers to extract features and perform classification tasks effectively.</li>
  <li><b>Model Training:</b> Utilized TensorFlow's image dataset API to split the data into training, validation, and test sets. Trained the model using the Adam optimizer and binary cross-entropy loss function. Monitored model performance on validation data to prevent overfitting.</li>
  <li><b>Model Evaluation:</b> Evaluated model performance metrics, including precision, recall, and binary accuracy, achieving a commendable accuracy of 93.5% on the test set.</li>
  <li><b>Prediction Demonstration:</b> Provided an example of model usage for making predictions on new images. Demonstrated the application of the trained model to classify images as "Happy" or "Sad" based on learned features.</li>
</ul>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Outcome: Successfully developed an image classification model achieving high accuracy in distinguishing between "Happy" and "Sad" images. Contributed to advancing the understanding and application of deep learning techniques for image analysis tasks.
</p>


<li>
  <h4 style="font-family: 'Comic Sans MS';">
    <a href="https://github.com/yourusername/Web_Content_Analysis">Web Content Analysis: Extracting Insights from Website Textual Data</a> [Python, LangChain, OpenAI]
  </h4>
</li>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Utilized advanced NLP techniques with LangChain, particularly leveraging the LangChain OpenAI module, to address diverse text processing challenges.
</p>
<ul style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  <li><b>Module Integration:</b> Integrated essential modules from LangChain and other libraries to streamline text processing workflows.</li>
  <li><b>API Key Configuration:</b> Configured environment variables for secure access to OpenAI's powerful API, ensuring seamless integration into the project environment.</li>
  <li><b>Library Management:</b> Managed library dependencies effectively by installing and updating the LangChain OpenAI library to ensure compatibility and access to the latest features.</li>
  <li><b>Module Utilization:</b> Leveraged various modules from LangChain OpenAI to perform tasks such as document loading, text chunking, embeddings, and vectorization, demonstrating proficiency in utilizing advanced NLP tools.</li>
  <li><b>Model Initialization:</b> Initialized OpenAI's language model instance with tailored parameters, fine-tuning settings like temperature and maximum tokens for optimal performance in text generation tasks.</li>
  <li><b>Data Acquisition:</b> Employed an asynchronous HTML loader to efficiently fetch and load data from specified URLs, enabling seamless integration of external text sources into the project pipeline.</li>
  <li><b>Text Processing:</b> Employed techniques such as text chunking to break down large HTML documents into manageable segments, facilitating efficient processing and analysis of textual data.</li>
  <li><b>Vectorization and Similarity Search:</b> Utilized OpenAI embeddings and FAISS for vectorization of document chunks and performed similarity search operations, enabling efficient retrieval of documents related to specified query strings.</li>
  <li><b>Result Visualization:</b> Implemented functionality to print documents similar to the provided query, providing actionable insights into the textual data corpus.</li>
</ul>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • This project exemplifies a comprehensive approach to NLP, showcasing proficiency in utilizing cutting-edge tools and methodologies to address complex text processing challenges effectively.
</p>

    </ol>

</section>
