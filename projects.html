---
layout: page
title: Projects
---
<h2 class="title" >PROJECTS</h2>
<!-- <section class="list">
    {% for post in site.posts %}
        {% if post.projects %}
            <div class="item {% if post.star %}star{% endif %}" >
                <a class="url" href="{% if post.externalLink %}{{ post.externalLink }}{% else %}{{ site.url }}{{ post.url }}{% endif %}">
                    <h3 class="title" style="font-family: 'Noto Serif';">{{ post.ct }}. {{ post.title }}</h3>
                </a>
            </div>
        {% endif %}
    {% endfor %} -->

    <ol class="skill-list" style="font-family: 'Comic Sans MS';">
    
        
        <li>
  <h4 style="font-family: 'Comic Sans MS';">
    <a href="https://github.com/umesh660/Image_Classification">Image Classification Model Development</a> [Python, TensorFlow, Keras]
  </h4>
</li>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Developed an image classification model using Python in a Google Colab environment leveraging TensorFlow and Keras libraries. The project aimed to classify images into two categories: "Happy" and "Sad".
</p>
<ul style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  <li><b>Data Preprocessing:</b> Implemented data preprocessing steps including image extension validation and removal of unsupported image files. Ensured data integrity and compatibility for model training.</li>
  <li><b>Model Development:</b> Constructed a convolutional neural network (CNN) architecture using Keras Sequential API. Designed the model with convolutional layers, max-pooling layers, and dense layers to extract features and perform classification tasks effectively.</li>
  <li><b>Model Training:</b> Utilized TensorFlow's image dataset API to split the data into training, validation, and test sets. Trained the model using the Adam optimizer and binary cross-entropy loss function. Monitored model performance on validation data to prevent overfitting.</li>
  <li><b>Model Evaluation:</b> Evaluated model performance metrics, including precision, recall, and binary accuracy, achieving a commendable accuracy of 93.5% on the test set.</li>
  <li><b>Prediction Demonstration:</b> Provided an example of model usage for making predictions on new images. Demonstrated the application of the trained model to classify images as "Happy" or "Sad" based on learned features.</li>
</ul>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Outcome: Successfully developed an image classification model achieving high accuracy in distinguishing between "Happy" and "Sad" images. Contributed to advancing the understanding and application of deep learning techniques for image analysis tasks.
</p>
<li>
  <h4 style="font-family: 'Comic Sans MS';">
    <a href="https://github.com/umesh660/Forecasting-Economic-Indicators-and-FTSE-100-A-Technical-Report">Forecasting Economic Indicators and FTSE 100: A Technical Report</a> [Python, ARIMA, Exponential Smoothing]
  </h4>
</li>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • This report forecasts UK economic indicators and the FTSE 100 index until December 2024 using exponential smoothing and ARIMA models on datasets from the UK Government Office for National Statistics (ONS).
</p>
<ul style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  <li><b>Data Preparation:</b> Sourced data from ONS, ensuring all datasets are monthly and cover the same period. Handled missing values and normalized the data.</li>
  <li><b>Forecasting Methods:</b> Applied exponential smoothing to forecast each series separately. Compared ARIMA and exponential smoothing for Average Weekly Earnings (K54D).</li>
  <li><b>Multivariate Regression Model:</b> Used the four series (K54D, EAFV, K226, JQ2J) to predict the FTSE 100 index, aligning datasets and developing a regression model.</li>
  <li><b>Results:</b> Presented forecasts for each series. Compared ARIMA and exponential smoothing for K54D. Evaluated the regression model for FTSE 100.</li>
</ul>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Conclusion: Summarized findings and provided recommendations.
</p>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Appendix: Python code descriptions for data preparation, exponential smoothing, ARIMA for K54D, and FTSE 100 regression model development and validation.
</p>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  This report provides robust predictions for economic indicators and the FTSE 100, aiding Future Stocks in informed decision-making.
</p>

<li>
  <h4 style="font-family: 'Comic Sans MS';">
    <a href="https://github.com/umesh660/Web-Content-Analysis-Using-Langchain">Web Content Analysis: Extracting Insights from Website Textual Data</a> [Python, LangChain, OpenAI]
  </h4>
</li>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Utilized advanced NLP techniques with LangChain, particularly leveraging the LangChain OpenAI module, to address diverse text processing challenges.
</p>
<ul style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  <li><b>Module Integration:</b> Integrated essential modules from LangChain and other libraries to streamline text processing workflows.</li>
  <li><b>API Key Configuration:</b> Configured environment variables for secure access to OpenAI's powerful API, ensuring seamless integration into the project environment.</li>
  <li><b>Library Management:</b> Managed library dependencies effectively by installing and updating the LangChain OpenAI library to ensure compatibility and access to the latest features.</li>
  <li><b>Module Utilization:</b> Leveraged various modules from LangChain OpenAI to perform tasks such as document loading, text chunking, embeddings, and vectorization, demonstrating proficiency in utilizing advanced NLP tools.</li>
  <li><b>Model Initialization:</b> Initialized OpenAI's language model instance with tailored parameters, fine-tuning settings like temperature and maximum tokens for optimal performance in text generation tasks.</li>
  <li><b>Data Acquisition:</b> Employed an asynchronous HTML loader to efficiently fetch and load data from specified URLs, enabling seamless integration of external text sources into the project pipeline.</li>
  <li><b>Text Processing:</b> Employed techniques such as text chunking to break down large HTML documents into manageable segments, facilitating efficient processing and analysis of textual data.</li>
  <li><b>Vectorization and Similarity Search:</b> Utilized OpenAI embeddings and FAISS for vectorization of document chunks and performed similarity search operations, enabling efficient retrieval of documents related to specified query strings.</li>
  <li><b>Result Visualization:</b> Implemented functionality to print documents similar to the provided query, providing actionable insights into the textual data corpus.</li>
</ul>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • This project exemplifies a comprehensive approach to NLP, showcasing proficiency in utilizing cutting-edge tools and methodologies to address complex text processing challenges effectively.
</p>
<li>
  <h4 style="font-family: 'Comic Sans MS';">
    <a href="https://github.com/yourusername/Kidney-Disease-Classification-MLflow-DVC">Kidney Disease Classification: Leveraging Deep Learning Models for Accurate Diagnosis</a> [Python, TensorFlow, MLflow, DVC]
  </h4>
</li>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • Implemented state-of-the-art deep learning techniques to classify kidney disease, using a robust workflow powered by MLflow and DVC.
</p>
<ul style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  <li><b>Experiment Tracking:</b> Utilized MLflow to track experiments, capturing metrics, parameters, and artifacts, ensuring reproducibility and facilitating comparison of different model runs.</li>
  <li><b>Data Version Control:</b> Employed DVC to manage datasets and machine learning pipelines, ensuring versioning of data and reproducibility of experiments.</li>
  <li><b>Model Training:</b> Developed and trained deep learning models using TensorFlow, fine-tuning hyperparameters to optimize performance for kidney disease classification.</li>
  <li><b>Pipeline Orchestration:</b> Designed and orchestrated machine learning pipelines, integrating DVC for streamlined data management and MLflow for seamless experiment tracking.</li>
  <li><b>CI/CD Integration:</b> Configured continuous integration and continuous deployment (CI/CD) pipelines using AWS and GitHub Actions to automate testing and deployment processes, enhancing workflow efficiency.</li>
  <li><b>Data Preprocessing:</b> Implemented preprocessing techniques including normalization and augmentation to prepare the kidney disease dataset for model training.</li>
  <li><b>Model Evaluation:</b> Conducted extensive model evaluation using various metrics to assess the performance and robustness of the kidney disease classification models.</li>
  <li><b>Deployment:</b> Set up deployment pipelines to automatically deploy trained models to a cloud environment using AWS, ensuring scalability and accessibility of the kidney disease classification service.</li>
  <li><b>Documentation and Reporting:</b> Provided comprehensive documentation and reports detailing the experiment setup, data processing steps, model training process, and evaluation results, ensuring transparency and reproducibility.</li>
</ul>
<p style="font-family: 'Comic Sans MS';font-size:14px;color:black;">
  • This project demonstrates expertise in deep learning, data management, and CI/CD practices, showcasing a complete end-to-end solution for kidney disease classification.
</p>

    </ol>

</section>
